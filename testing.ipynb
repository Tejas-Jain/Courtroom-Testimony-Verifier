{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\CTV\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "load_dotenv()\n",
    "from sentence_transformers.util import semantic_search\n",
    "\n",
    "model_id = os.getenv(\"model_id\")\n",
    "hf_token = os.getenv(\"hf_token\")\n",
    "api_url = f\"https://api-inference.huggingface.co/pipeline/feature-extraction/{model_id}\"\n",
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "\n",
    "\n",
    "def getEmbeddings(texts):\n",
    "    response = requests.post(api_url, headers=headers, json={\"inputs\": texts, \"options\":{\"wait_for_model\":True}})\n",
    "    embeddedData = response.json()\n",
    "    return torch.FloatTensor(embeddedData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"How do I get a replacement Medicare card?\",\n",
    "        \"What is the monthly premium for Medicare Part B?\",\n",
    "        \"How do I terminate my Medicare Part B (medical insurance)?\",\n",
    "        \"How do I sign up for Medicare?\",\n",
    "        \"Can I sign up for Medicare Part B if I am working and have health insurance through an employer?\",\n",
    "        \"How do I sign up for Medicare Part B if I already have Part A?\",\n",
    "        \"What are Medicare late enrollment penalties?\",\n",
    "        \"What is Medicare and who can get it?\",\n",
    "        \"How can I get help with my Medicare Part A and Part B premiums?\",\n",
    "        \"What are the different parts of Medicare?\",\n",
    "        \"Will my Medicare premiums be higher because of my higher income?\",\n",
    "        \"What is TRICARE ?\",\n",
    "        \"Should I sign up for Medicare Part B if I have Veterans' Benefits?\"]\n",
    "# dataset_embeddings = getEmbeddings(texts)\n",
    "\n",
    "\n",
    "questions = [\"How can Medicare help me?\", \n",
    "            \"What are the benefits of Insurance\", \n",
    "            \"What is Medicare and who can get it?\"]\n",
    "# query_embeddings = getEmbeddings(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[{'corpus_id': 8, 'score': 0.7565304636955261}]]\n",
      "1 [[{'corpus_id': 9, 'score': 0.3491109013557434}]]\n",
      "2 [[{'corpus_id': 7, 'score': 1.0000001192092896}]]\n"
     ]
    }
   ],
   "source": [
    "def mis_matches(dataset, queryset, threshold=0.9):\n",
    "    dataset_embeddings = getEmbeddings(dataset)\n",
    "    query_embeddings = getEmbeddings(queryset)\n",
    "    ans = []\n",
    "    for index, embedding in enumerate(query_embeddings):\n",
    "        hits = semantic_search(embedding, dataset_embeddings, top_k=1)\n",
    "        print(index, hits)\n",
    "        # if hits[0][0]['score']>threshold:\n",
    "        #     ans.append([index, hits[0][0]['corpus_id'], hits[0][0]['score']])\n",
    "        #     print([dataset[hits[i]['corpus_id']] for i in range(len(hits))])\n",
    "    # print(\"Ans:\", ans)\n",
    "\n",
    "mis_matches(texts, questions, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 7, 1.0000001192092896]]\n"
     ]
    }
   ],
   "source": [
    "def mis_matches(dataset, queryset, threshold=0.9):\n",
    "    dataset_embeddings = getEmbeddings(dataset)\n",
    "    query_embeddings = getEmbeddings(queryset)\n",
    "    hits = semantic_search(query_embeddings, dataset_embeddings, top_k=1)\n",
    "    ans = [\n",
    "        [index, hit[0]['corpus_id'], hit[0]['score']] \n",
    "        for index, hit in enumerate(hits)\n",
    "        if hit[0]['score']>threshold\n",
    "    ]\n",
    "    # print(ans)\n",
    "    return ans\n",
    "\n",
    "mis_matches(texts, questions, 0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
